<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Site Info -->
    <title>Mit Patel - Blog</title>
    <meta name="description" content="Mit Patel - Highly experienced and results-oriented lecturer with 7 years of expertise in educating and guiding students in mathematics, statistics, and programming. Possessing a Master&#39;s degree in Data Analytics and a strong foundation in Information Technology, I have successfully developed and delivered comprehensive curricula in core subjects such as Machine Learning, Data Analysis, and Python. Proven ability to simplify complex concepts, enhance student performance, and foster a positive learning environment. Driven to leverage my analytical, problem-solving, and programming skills, coupled with continuous upskilling in cutting-edge AI/ML technologies (including LLMs and MLOps), to contribute to innovative solutions in the Data Science domain, developing and implementing advanced machine learning models to solve complex business problems.">
    <meta name="author" content="Mit Patel">

    <!-- Open Graph Tags: The title of the page for social media sharing. It can match the title tag or be more descriptive. -->
    <meta property="og:title" content="Mit Patel">

    <!-- Open Graph Tags: Typically set to "website" for static sites or "article" for content-heavy pages. -->
    <meta property="og:type" content="website">

    <!-- Open Graph Tags: The URL of the page, used to ensure link previews resolve to the correct page. -->
    <!-- base_url -->
    <meta property="og:url" content="127.0.0.1:5500/blog.html">

    <!-- Open Graph Tags: URL of an image that represents the page. Useful for link previews. -->
    <!-- base_url -->
    <meta property="og:image" content="127.0.0.1:5500/portfolio_media/photo_2.jpg">

    <!-- Open Graph Tags: Provides an alternative text for the image to improve accessibility. -->
    <meta property="og:image:alt" content="Mit Patel Profile Image">

    <!-- Preconnect for Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    <!-- Custom Font -->
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&family=Nunito:ital,wght@0,200..1000;1,200..1000&display=swap"
          rel="stylesheet">

    <!-- Stylesheet -->
    <link rel="stylesheet" href="css/modern_normalize.css" />
    <link rel="stylesheet" href="css/html5bp.css">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/resume.css">

    <!-- Set a theme color that matches your website's primary color -->
    <meta name="theme-color" content="#fafafa">

    <!-- Favicon for all browsers -->
    <link rel="icon" href="/favicon.ico" sizes="any">
    <link rel="icon" href="/icon.svg" type="image/svg+xml">

    <!-- Apple touch icon for iOS devices -->
    <link rel="apple-touch-icon" sizes="180x180" href="/icon.png">

    <!-- Web app manifest for Progressive Web Apps -->
    <link rel="manifest" href="/site.webmanifest">

    <!-- Content Security Policy: Uncomment to enhance security by restricting where content can be loaded from (useful for preventing certain attacks like XSS). Update if adding external sources (e.g., Google Fonts, Bootstrap CDN, analytics, etc). -->
    <!-- <meta http-equiv="Content-Security-Policy" content=" default-src 'self'; script-src 'self' code.jquery.com; style-src 'self' fonts.googleapis.com; font-src fonts.gstatic.com; img-src 'self' images.examplecdn.com; "> -->
  </head>

<body>
    <header class="page-header">
        <div class="container">
            <div class="header-top flex-responsive">
                <div class="header-info">
                
                    <!-- name -->
                    <h1>Mit Patel's Blog</h1>
                    <nav>
                        <ul class="inline-list flex-responsive">
                            <li><a href="index.html">Home</a></li>
                            <li><a href="resume.html">Resume</a></li>
                        </ul>
                    </nav>
                </div>
            </div>
        </div>
    </header>
    <div class="page-content">
        <div class="container">
            <main>
                <section>
                    <h2 class="section-heading">Recent Posts</h2>
                    
                    <!-- blogs -->
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/AI-Nutritionist-Using-Gemini-Pro">Computer Vision Meets Nutrition: My Food Analysis Journey</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-07-14</p>
                        
                            <p>My food analysis app was identifying pizza as salad, and I was losing my mind. The <strong>computer vision</strong> component seemed simple - just send an image to <strong>Google Gemini</strong> and get nutritional data back. Wrong. The real challenge was <strong>prompt engineering</strong> for consistent responses. My first attempts returned nutrition data in random formats, making it impossible to parse. I spent weeks crafting the perfect prompt structure, learning that <strong>AI models need very specific instructions</strong>. The <strong>image preprocessing</strong> with <strong>PIL</strong> was another headache - different image formats and sizes broke my pipeline constantly. Users were uploading everything from blurry phone photos to high-res professional shots. I had to implement <strong>robust image handling</strong> and <strong>error recovery</strong>. The breakthrough came when I standardized the <strong>prompt template</strong> and added <strong>response validation</strong>. Initially, the app would crash on edge cases, but proper <strong>exception handling</strong> made it production-ready. This project taught me that <strong>multimodal AI requires careful orchestration</strong> between vision and language models. The key insight? <strong>Consistent prompts lead to consistent results</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Google Gemini AI</span>
                                
                                    <span class="tag">PIL</span>
                                
                                    <span class="tag">Computer Vision</span>
                                
                                    <span class="tag">Image Processing</span>
                                
                                    <span class="tag">Prompt Engineering</span>
                                
                                    <span class="tag">Data Visualization</span>
                                
                                    <span class="tag">Multimodal AI</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/yt_transcriber">YouTube Summarizer: When APIs Don&#39;t Cooperate</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-07-14</p>
                        
                            <p>My YouTube summarizer worked perfectly on my test videos, then failed spectacularly on real content. The <strong>YouTube Transcript API</strong> was more finicky than expected - many videos don't have transcripts, others have auto-generated gibberish. The <strong>80% time reduction</strong> only became reality after I implemented <strong>robust error handling</strong> and <strong>fallback mechanisms</strong>. My initial approach crashed whenever a video lacked proper transcripts. The breakthrough came when I learned to <strong>validate transcript quality</strong> before processing. The <strong>Google Gemini Pro</strong> summarization was inconsistent - some summaries were too technical, others too basic. I had to implement <strong>adaptive prompting</strong> based on video content type. The <strong>rate limiting</strong> on both APIs was a constant challenge during testing. I learned about <strong>exponential backoff</strong> and <strong>request queuing</strong> the hard way. The most frustrating part was handling <strong>different video types</strong> - educational content summarized well, but entertainment videos were hit-or-miss. I had to build <strong>content classification</strong> to adjust summarization strategies. This project taught me that <strong>API integrations require defensive programming</strong>. The key lesson? <strong>Always have backup plans when dealing with external services</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Google Generative AI SDK</span>
                                
                                    <span class="tag">YouTube Transcript API</span>
                                
                                    <span class="tag">Google Gemini Pro API</span>
                                
                                    <span class="tag">Text Summarization</span>
                                
                                    <span class="tag">Rate Limiting</span>
                                
                                    <span class="tag">API Integration</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/genai-with-aws-bedrock-lambda-apigateway">Serverless Struggles: When Lambda Functions Have Limits</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-07-02</p>
                        
                            <p>My first <strong>serverless deployment</strong> was a disaster. The <strong>Lambda function</strong> kept timing out because I didn't understand the <strong>15-minute execution limit</strong>. I was trying to generate long-form content that exceeded these constraints. The breakthrough came when I implemented <strong>streaming responses</strong> and <strong>chunked processing</strong>. <strong>IAM permissions</strong> were my nemesis - I spent days debugging why my function couldn't access <strong>S3 buckets</strong>. The learning curve for <strong>AWS Bedrock</strong> was steep, especially understanding how to optimize <strong>LLM API calls</strong>. My content generation was inconsistent until I learned proper <strong>prompt engineering</strong> and <strong>response formatting</strong>. The most frustrating part was debugging <strong>cold starts</strong> - my API would randomly become slow for the first few requests. This project taught me that <strong>serverless architecture requires different thinking</strong> than traditional deployments. The key lesson? <strong>Understand your platform's constraints before building</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">AWS Bedrock</span>
                                
                                    <span class="tag">Lambda</span>
                                
                                    <span class="tag">API Gateway</span>
                                
                                    <span class="tag">S3</span>
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Boto3</span>
                                
                                    <span class="tag">IAM</span>
                                
                                    <span class="tag">Meta Llama 3</span>
                                
                                    <span class="tag">Scalable Cloud Infrastructure</span>
                                
                                    <span class="tag">Serverless Architecture Patterns</span>
                                
                                    <span class="tag">End-to-End Serverless Solution</span>
                                
                                    <span class="tag">Timeout Management</span>
                                
                                    <span class="tag">AI Model Integration</span>
                                
                                    <span class="tag">Robust Error Handling</span>
                                
                                    <span class="tag">Logging Strategies</span>
                                
                                    <span class="tag">CloudWatch</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/aws-sagemaker">When SageMaker Humbled Me: A Cloud-Native ML Reality Check</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-25</p>
                        
                            <p>My confidence took a hit when my first SageMaker training job failed with a cryptic error message. I had assumed cloud ML would be straightforward - just upload data and train, right? Wrong. The learning curve was steep, especially understanding <strong>IAM roles</strong> and <strong>S3 permissions</strong>. I wasted an entire weekend debugging why my training script couldn't access the data bucket. The real challenge was transitioning from local Jupyter notebooks to <strong>cloud-native architecture</strong>. My breakthrough moment came when I finally grasped the importance of <strong>proper error handling</strong> and <strong>logging strategies</strong>. Initially, I was flying blind when jobs failed, but implementing comprehensive logging made debugging much easier. The mobile price prediction accuracy improved from 78% to 95% once I properly configured <strong>hyperparameter tuning</strong>. This project taught me that cloud platforms are powerful but require disciplined engineering practices. The key lesson? <strong>Infrastructure is just as important as the algorithm</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">AWS SageMaker</span>
                                
                                    <span class="tag">S3</span>
                                
                                    <span class="tag">IAM</span>
                                
                                    <span class="tag">Boto3</span>
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">CloudWatch</span>
                                
                                    <span class="tag">scikit-learn</span>
                                
                                    <span class="tag">Pandas</span>
                                
                                    <span class="tag">Joblib</span>
                                
                                    <span class="tag">Jupyter Notebooks</span>
                                
                                    <span class="tag">Cloud-native Architecture</span>
                                
                                    <span class="tag">MLOps Best Practices</span>
                                
                                    <span class="tag">Model Versioning</span>
                                
                                    <span class="tag">Model Registry</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Text-Summarizer">Transformer Fine-Tuning: When GPUs Became My Best Friend</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-24</p>
                        
                            <p>Fine-tuning the Pegasus model was my first real encounter with <strong>GPU computing</strong>, and it was humbling. My initial attempts kept running out of memory, and I didn't understand why. The breakthrough came when I learned about <strong>gradient accumulation</strong> and <strong>batch size optimization</strong>. I spent days tweaking hyperparameters, watching training losses bounce around unpredictably. The real challenge was getting the <strong>data preprocessing pipeline</strong> right - tokenization issues caused my model to produce gibberish summaries initially. I had to rebuild the entire <strong>data ingestion workflow</strong> three times before getting it right. The ROUGE scores were disappointing at first, but implementing <strong>proper evaluation metrics</strong> helped me understand what the model was actually learning. Docker deployment was another headache - my container kept crashing due to memory issues. This project taught me that <strong>transformer models are powerful but resource-intensive</strong>. The key lesson? <strong>Understanding your compute constraints is crucial for successful model deployment</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">HuggingFace Transformers</span>
                                
                                    <span class="tag">PyTorch</span>
                                
                                    <span class="tag">FastAPI</span>
                                
                                    <span class="tag">Docker</span>
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">End-to-End ML Pipeline</span>
                                
                                    <span class="tag">Modular Pipeline Architecture</span>
                                
                                    <span class="tag">Weights &amp; Biases</span>
                                
                                    <span class="tag">Containerized Deployment</span>
                                
                                    <span class="tag">MLOps Practices</span>
                                
                                    <span class="tag">ROUGE Evaluation</span>
                                
                                    <span class="tag">Automated Pipeline Stages</span>
                                
                                    <span class="tag">Experiment Tracking</span>
                                
                                    <span class="tag">RESTful API</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Student-Performance-Project">Student Performance Prediction: When Simple Isn&#39;t Always Better</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-21</p>
                        
                            <p>I overcomplicated everything initially, trying to use advanced deep learning for what turned out to be a <strong>classical ML problem</strong>. My neural network was overfitting terribly, and I was chasing diminishing returns. The humbling moment came when a simple <strong>Random Forest outperformed my complex architecture</strong>. Deployment on <strong>AWS Elastic Beanstalk</strong> was my first real production experience, and it was messier than expected. My Flask app kept crashing due to memory leaks I hadn't noticed during local testing. The <strong>model comparison framework</strong> took longer to build than the actual models - I learned that <strong>proper evaluation infrastructure</strong> is crucial. The biggest challenge was handling <strong>real-time predictions</strong> reliably. Users would input edge cases that broke my preprocessing pipeline. This project taught me that <strong>production systems need robust error handling</strong> and that <strong>simpler solutions often work better</strong>. The key insight? <strong>Focus on reliability over complexity</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Flask</span>
                                
                                    <span class="tag">scikit-learn pipeline</span>
                                
                                    <span class="tag">Pandas</span>
                                
                                    <span class="tag">AWS EC2</span>
                                
                                    <span class="tag">Elastic Beanstalk</span>
                                
                                    <span class="tag">ML Pipelines</span>
                                
                                    <span class="tag">Model Deployment</span>
                                
                                    <span class="tag">Cloud Deployment (AWS)</span>
                                
                                    <span class="tag">End-to-End ML Web Application</span>
                                
                                    <span class="tag">Modular Architecture</span>
                                
                                    <span class="tag">Comprehensive Loggings</span>
                                
                                    <span class="tag">Production-ready Systems</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Network-Security-System-MLOps-Project">From Messy Data to Production MLOps: My Network Security Journey</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-18</p>
                        
                            <p>Building this network security system taught me that <strong>real-world data is never clean</strong>. My biggest challenge was handling inconsistent URL formats and missing network traffic labels. I spent weeks debugging why my model performed well locally but failed in production - turns out I hadn't properly handled data drift. The breakthrough came when I implemented proper <strong>data validation schemas</strong> and <strong>drift detection</strong>. I learned to always validate data at every pipeline stage, not just during training. Another major hurdle was orchestrating multiple AWS services - my first deployment failed spectacularly because I misconfigured IAM permissions. After three sleepless nights, I finally got the <strong>CI/CD pipeline</strong> working smoothly. The key takeaway? <strong>Always build with production in mind from day one</strong>, not as an afterthought. This project taught me that MLOps isn't just about deploying models - it's about building resilient systems that can handle real-world chaos.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">MLflow</span>
                                
                                    <span class="tag">Dagshub</span>
                                
                                    <span class="tag">AWS (EC2, ECR, S3)</span>
                                
                                    <span class="tag">MongoDB</span>
                                
                                    <span class="tag">CI/CD automation</span>
                                
                                    <span class="tag">Schema Validation</span>
                                
                                    <span class="tag">Experiment Tracking</span>
                                
                                    <span class="tag">FastAPI</span>
                                
                                    <span class="tag">Modular Pipeline Architecture</span>
                                
                                    <span class="tag">Production-ready MLOps Pipeline</span>
                                
                                    <span class="tag">Automated Threat Detection</span>
                                
                                    <span class="tag">End-to-End ML Lifecycle Management</span>
                                
                                    <span class="tag">Real-Time Prediction API</span>
                                
                                    <span class="tag">Docker</span>
                                
                                    <span class="tag">Drift Detection Capabilities</span>
                                
                                    <span class="tag">Automated Model Retraining</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/financial-ai-analyst">Multi-Agent Chaos: When AI Agents Wouldn&#39;t Cooperate</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-15</p>
                        
                            <p>My agents were fighting each other instead of collaborating. The financial analysis system was supposed to have smooth <strong>agent coordination</strong>, but initially, they kept making redundant API calls and conflicting recommendations. I underestimated how complex <strong>task distribution</strong> would be. The breakthrough came when I implemented proper <strong>state management</strong> and <strong>communication protocols</strong> between agents. Debugging was a nightmare - I had to build custom logging to track which agent was doing what. The Yahoo Finance API rate limits caught me off guard, causing the system to crash during peak trading hours. I solved this by implementing <strong>intelligent caching</strong> and <strong>request queuing</strong>. The most satisfying moment was seeing the research time drop from hours to minutes once the agents learned to work together. This project taught me that <strong>multi-agent systems require careful orchestration</strong> - they're not just multiple independent scripts. The key insight? <strong>Agent coordination is harder than individual agent intelligence</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Agno</span>
                                
                                    <span class="tag">Groq</span>
                                
                                    <span class="tag">DuckDuckGoTools</span>
                                
                                    <span class="tag">YFinanceTools</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Google API</span>
                                
                                    <span class="tag">Multi-Agent AI System</span>
                                
                                    <span class="tag">Specialized AI Agents</span>
                                
                                    <span class="tag">Agent Coordination Patterns</span>
                                
                                    <span class="tag">Task Distribution Algorithms</span>
                                
                                    <span class="tag">Financial Data Analysis</span>
                                
                                    <span class="tag">Automated Report Generation</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Video-Summarizer">Video AI Agent: When Multimodal Meets Complex</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-15</p>
                        
                            <p>Building a <strong>video summarizer</strong> that could also search the web sounded ambitious, and it was. My <strong>agent-based architecture</strong> was overly complex initially - I was trying to coordinate multiple AI models and web APIs without proper orchestration. The <strong>Gemini 2.0 Flash</strong> video processing was impressive but slow, and users were getting impatient. I had to implement <strong>loading indicators</strong> and <strong>progress tracking</strong> to manage expectations. The real challenge was <strong>combining video insights</strong> with <strong>web search results</strong> coherently. My first attempts produced disjointed summaries that read like random facts. The breakthrough came when I redesigned the <strong>agent coordination</strong> system to have proper <strong>information flow</strong>. The <strong>DuckDuckGo API</strong> integration was reliable, but managing <strong>rate limits</strong> and <strong>search quality</strong> required careful tuning. I learned that <strong>agent systems need clear responsibilities</strong> and <strong>communication protocols</strong>. The most satisfying moment was when the app started producing comprehensive analyses that users actually found valuable. This project taught me that <strong>multimodal AI requires careful system design</strong>. The key insight? <strong>Complex systems need simple, clear interfaces</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Google Gemini 2.0</span>
                                
                                    <span class="tag">Agno Framework</span>
                                
                                    <span class="tag">DuckDuckGo API</span>
                                
                                    <span class="tag">Multimodal AI</span>
                                
                                    <span class="tag">Agent Architecture</span>
                                
                                    <span class="tag">Video Processing</span>
                                
                                    <span class="tag">Workflow Orchestration</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Basic-Agents">Vector Database Nightmares: When Embeddings Don&#39;t Embed</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-06-13</p>
                        
                            <p>Building the <strong>multi-tier agent system</strong> seemed straightforward until I hit the vector database wall. My embeddings weren't clustering properly, and similarity search was returning irrelevant results. I spent weeks debugging why <strong>LanceDB</strong> wasn't performing as expected - turns out my <strong>chunking strategy</strong> was terrible. The real challenge was <strong>coordinating multiple AI models</strong> with different response formats and latencies. My agents kept timing out or producing conflicting outputs. The breakthrough came when I implemented <strong>proper error handling</strong> and <strong>fallback mechanisms</strong>. Initially, I naively assumed all AI models would behave similarly, but each had unique quirks. The financial analysis became much more accurate once I figured out how to <strong>balance different data sources</strong> and <strong>agent expertise</strong>. This project taught me that <strong>vector databases require careful tuning</strong> and that <strong>agent coordination is an art, not a science</strong>. The key insight? <strong>Different AI models need different handling strategies</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Agno</span>
                                
                                    <span class="tag">Google Gemini</span>
                                
                                    <span class="tag">Groq</span>
                                
                                    <span class="tag">Lancedb</span>
                                
                                    <span class="tag">Google API</span>
                                
                                    <span class="tag">DuckDuckGo</span>
                                
                                    <span class="tag">Multi-tier AI Agents Architecture</span>
                                
                                    <span class="tag">Knowledge Management</span>
                                
                                    <span class="tag">Hybrid Search Capabilities</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/ATS-gemini-1">ATS Optimization: When AI Meets Recruiting</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-05-27</p>
                        
                            <p>My ATS analyzer was giving every resume a 20% match score, regardless of content. I assumed <strong>resume parsing</strong> would be straightforward - extract text and compare keywords. The reality was much messier. <strong>PDF text extraction</strong> with <strong>PyPDF2</strong> was failing on formatted resumes, missing crucial information. Some resumes were images disguised as PDFs, others had complex layouts that scrambled text order. The breakthrough came when I implemented <strong>robust text preprocessing</strong> and <strong>content validation</strong>. The <strong>real-time matching algorithm</strong> was my biggest challenge - I had to learn how <strong>ATS systems actually work</strong> to provide accurate feedback. My initial keyword matching was too simplistic, missing synonyms and context. I had to build a <strong>semantic similarity system</strong> that understood that 'machine learning' and 'ML' are the same thing. The <strong>prompt engineering</strong> for consistent AI responses took weeks to perfect. Users needed actionable feedback, not generic advice. The most rewarding moment was when users started getting interview callbacks after using the tool. This project taught me that <strong>AI tools need domain knowledge</strong> to provide real value. The key insight? <strong>Understanding the problem domain is as important as the technical implementation</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Google Gemini AI</span>
                                
                                    <span class="tag">PyPDF2</span>
                                
                                    <span class="tag">API Integration</span>
                                
                                    <span class="tag">Prompt Engineering</span>
                                
                                    <span class="tag">PDF Processing</span>
                                
                                    <span class="tag">Text Analysis</span>
                                
                                    <span class="tag">Matching Algorithms</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Text-to-SQL-Using-Gemini-Pro">Text-to-SQL: When Natural Language Meets Databases</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-05-27</p>
                        
                            <p>My text-to-SQL converter was generating syntactically correct queries that returned empty results. The <strong>95% accuracy</strong> claim was misleading - the SQL was valid, but the logic was wrong. Users would ask 'show me customers from last month' and get results from last year. The challenge was teaching the AI to understand <strong>database schema</strong> and <strong>business logic</strong> simultaneously. I spent weeks building <strong>comprehensive prompt templates</strong> that included table relationships, data types, and business rules. The real breakthrough came when I implemented <strong>query validation</strong> and <strong>result verification</strong>. The <strong>SQLite database</strong> integration was straightforward, but making the AI understand <strong>foreign key relationships</strong> was complex. I had to provide extensive <strong>schema documentation</strong> in the prompts. The most frustrating part was handling <strong>ambiguous queries</strong> - users rarely ask precise questions. 'Show me sales' could mean today's sales, monthly sales, or sales by region. I learned to implement <strong>clarification mechanisms</strong> and <strong>smart defaults</strong>. The <strong>error handling</strong> system became crucial - users needed to understand why their query failed. This project taught me that <strong>natural language interfaces need extensive domain knowledge</strong>. The key lesson? **Context matters more tha</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Google Gemini Pro API</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">SQLite</span>
                                
                                    <span class="tag">Natural Language Processing</span>
                                
                                    <span class="tag">REST APIs</span>
                                
                                    <span class="tag">Database Design</span>
                                
                                    <span class="tag">Text-to-SQL</span>
                                
                                    <span class="tag">Query Optimization</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Document-QA-Using-Gemma-Groq">RAG Reality: When Documents Refuse to Answer Questions</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-04-23</p>
                        
                            <p>My RAG system was confidently giving wrong answers, and I couldn't figure out why. The document <strong>chunking strategy</strong> was my biggest mistake - I was splitting text randomly instead of preserving semantic meaning. Users were getting frustrated with irrelevant responses, and I was losing confidence in the system. The breakthrough came when I implemented <strong>semantic chunking</strong> and <strong>overlap strategies</strong>. The <strong>FAISS vector database</strong> performance was another challenge - queries were taking too long, especially with large document collections. I had to learn about <strong>index optimization</strong> and <strong>query batching</strong>. The most embarrassing moment was when the system couldn't answer basic questions about documents it had just processed. This led me to implement <strong>context verification</strong> and <strong>confidence scoring</strong>. The <strong>sub-second response time</strong> achievement only came after extensive <strong>caching optimization</strong>. This project taught me that <strong>RAG systems need careful tuning of every component</strong>. The key lesson? <strong>Garbage in, garbage out applies especially to document processing</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">LangChain</span>
                                
                                    <span class="tag">Text Chunking</span>
                                
                                    <span class="tag">PDF parsing</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">FAISS</span>
                                
                                    <span class="tag">Google API</span>
                                
                                    <span class="tag">PyPDF2</span>
                                
                                    <span class="tag">Vector Embeddings</span>
                                
                                    <span class="tag">Similarity Search</span>
                                
                                    <span class="tag">Document Processing</span>
                                
                                    <span class="tag">Semantic Search</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Chat-With-PDF-Using-Gemini-Pro">PDF Chat Debugging: When RAG Meets Reality</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-04-21</p>
                        
                            <p>Building my first <strong>RAG system</strong> felt straightforward until documents started 'lying' to me. My PDF chat was confidently giving wrong answers, and I couldn't understand why. The chunking strategy was my downfall - I was splitting text arbitrarily, destroying context completely. After days of debugging, I realized my <strong>vector embeddings</strong> weren't capturing semantic meaning properly. The breakthrough came when I implemented <strong>sliding window chunking</strong> with proper overlap. <strong>FAISS indexing</strong> was another learning curve - my similarity search was returning irrelevant chunks consistently. I had to rebuild the entire <strong>embedding pipeline</strong> twice before understanding how <strong>LangChain</strong> actually processes documents. The most frustrating part was <strong>conversation memory</strong> - my chatbot kept forgetting previous questions mid-conversation. Once I figured out <strong>session state management</strong> in Streamlit, everything clicked. This project taught me that <strong>RAG isn't just about retrieval</strong> - it's about understanding how documents should be processed for AI consumption. The key lesson? <strong>Context preservation matters more than perfect similarity scores</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">LangChain</span>
                                
                                    <span class="tag">Google Gemini Pro</span>
                                
                                    <span class="tag">FAISS</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">PyPDF2</span>
                                
                                    <span class="tag">Vector Embeddings</span>
                                
                                    <span class="tag">RAG Architecture</span>
                                
                                    <span class="tag">Document Processing</span>
                                
                                    <span class="tag">NLP Pipeline</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Invoice-Extractor-Using-Gemini-Pro">Invoice Processing Hell: When AI Meets Accounting</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-04-19</p>
                        
                            <p>My invoice extractor was working perfectly... until I tested it with real invoices. The <strong>multi-language support</strong> I thought I had implemented was failing spectacularly on anything that wasn't English. German invoices were returning gibberish, and Japanese ones crashed the system entirely. The <strong>80% time reduction</strong> only came after I completely redesigned the <strong>text extraction pipeline</strong>. My initial approach using simple <strong>OCR</strong> was too naive - invoice layouts vary wildly across companies and countries. The breakthrough was understanding that <strong>Gemini Pro's multimodal capabilities</strong> could handle both text and layout analysis simultaneously. I had to learn <strong>advanced prompt engineering</strong> to make the AI understand invoice structure, not just text content. The <strong>95% accuracy</strong> achievement required building a <strong>validation system</strong> that cross-checked extracted data for consistency. Users were uploading scanned PDFs, photos, and digital invoices - each requiring different processing strategies. The most challenging part was handling <strong>currency conversion</strong> and <strong>regional number formats</strong>. This project taught me that <strong>document processing AI needs domain expertise built into prompts</strong>. The key insight? <strong>Real-world documents are messier than test data</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Google Gemini Pro</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Computer Vision</span>
                                
                                    <span class="tag">Document Processing</span>
                                
                                    <span class="tag">OCR</span>
                                
                                    <span class="tag">Multimodal AI</span>
                                
                                    <span class="tag">API Integration</span>
                                
                                    <span class="tag">Natural Language Processing</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/QA-Chatbot-Using-Gemini-Pro">Chatbot Evolution: Three Versions of Learning</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-04-19</p>
                        
                            <p>My first chatbot was stateless and stupid. Version 1 couldn't remember anything beyond the current message, making conversations frustrating. I thought adding <strong>session state</strong> would be simple - just store messages in a list, right? Wrong. <strong>Memory management</strong> in Streamlit was more complex than expected. The app kept running out of memory during long conversations, and I didn't understand why. Version 2 introduced <strong>conversation history</strong>, but the <strong>context window</strong> limitations of <strong>Gemini AI</strong> meant older messages got truncated unpredictably. Users would reference something from earlier in the conversation, and the bot would be clueless. The breakthrough came in Version 3 when I implemented <strong>intelligent context management</strong> - summarizing old conversations and maintaining relevant context. <strong>Streaming responses</strong> were another challenge - I wanted real-time typing effects, but handling <strong>API streaming</strong> while maintaining state was tricky. The most satisfying moment was when users started having natural, flowing conversations with the bot. This project taught me that <strong>conversational AI is about managing context, not just generating responses</strong>. The key lesson? <strong>Progressive iteration leads to better user experiences</strong></p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Google Gemini AI</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">RESTful API</span>
                                
                                    <span class="tag">Session Management</span>
                                
                                    <span class="tag">Streaming Responses</span>
                                
                                    <span class="tag">Context Awareness</span>
                                
                                    <span class="tag">Web Development</span>
                                
                            
                        </div>

                    </article>
                    
                    <article class="blog-post">
                        <h3 class="post-meta">
                            
                                <a href="https://github.com/GoJo-Rika/Image-Application-Using-Gemini-Pro">Multimodal AI Suite: When Simple Becomes Complex</a>
                            
                        </h3>
                        
                        <p class="section-label">Published on: 2025-04-17</p>
                        
                            <p>What started as a simple demo became a lesson in <strong>multimodal AI complexity</strong>. I wanted to showcase <strong>text generation</strong> and <strong>image analysis</strong> using <strong>Gemini models</strong>, but managing <strong>two different AI endpoints</strong> was trickier than expected. The <strong>Gemini 2.0 Flash</strong> and <strong>Flash Lite</strong> models had different response times and formats, causing UI inconsistencies. My biggest mistake was not implementing <strong>proper error handling</strong> initially - when one model failed, the entire app would crash. The real challenge was <strong>API key management</strong> and <strong>rate limiting</strong>. I was hitting usage limits during testing, learning about <strong>request throttling</strong> the hard way. The breakthrough came when I implemented <strong>fallback mechanisms</strong> and <strong>graceful degradation</strong>. Users could still use one feature even if another failed. <strong>Streamlit state management</strong> across multiple pages was another learning curve - I had to understand how to persist data between different app components. This project taught me that <strong>multiple AI models require orchestration strategies</strong>. The key lesson? <strong>Always plan for API failures and have backup strategies</strong>.</p>
                        
                        
                        <div class="tech-stack">
                            
                                
                                    <span class="tag">Python</span>
                                
                                    <span class="tag">Streamlit</span>
                                
                                    <span class="tag">Google Gemini 2.0</span>
                                
                                    <span class="tag">Multimodal AI</span>
                                
                                    <span class="tag">Image Processing Pipeline</span>
                                
                                    <span class="tag">API Security</span>
                                
                                    <span class="tag">Real-time Processing</span>
                                
                                    <span class="tag">UI/UX Design</span>
                                
                            
                        </div>

                    </article>
                    
                </section>
            </main>
        </div>
    </div>
    <footer class="page-footer">
        <div class="container">
            <p> 2025 Mit Patel. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>